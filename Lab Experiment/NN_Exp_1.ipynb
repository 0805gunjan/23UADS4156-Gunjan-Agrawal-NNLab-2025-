{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### WAP to implement the Perceptron Learning Algorithm using numpy in Python. Evaluate performance of a single perceptron for NAND and XOR truth tables as input dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Description of Model\n",
    "##### A perceptron is a binary classifier that separates data with a linear decision boundary. It is trained using Perceptron Learning Rule, which updates the weights iteratively to reduce misclassification.\n",
    "##### We apply activation function i.e. step function in the model and train the model by learing algorithmn of perceptron. We use the dataset of NAND ans XOR and apply the perceptron learning rule."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation of Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAND Perceptron Accuracy: 100.00%\n",
      "XOR Perceptron Accuracy: 50.00%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def step_function(x):\n",
    "    #Step Activation Function\n",
    "    return 1 if x >= 0 else 0\n",
    "\n",
    "class Perceptron:\n",
    "    def __init__(self, input_size, learning_rate=0.1, epochs=100):\n",
    "        # Initializing weights and bias\n",
    "        self.weights = np.random.rand(input_size + 1)  # +1 for bias\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "\n",
    "    def predict(self, x):\n",
    "        # Pridiction of output of given x\n",
    "        x = np.insert(x, 0, 1)  # Add bias term\n",
    "        return step_function(np.dot(self.weights, x))\n",
    "\n",
    "    def train(self, X, y):\n",
    "        #Train the perceptron by learing rate\n",
    "        for _ in range(self.epochs):\n",
    "            for i in range(len(X)):\n",
    "                x_i = np.insert(X[i], 0, 1)  # Add bias term\n",
    "                y_pred = step_function(np.dot(self.weights, x_i))\n",
    "                error = y[i] - y_pred\n",
    "                self.weights += self.learning_rate * error * x_i\n",
    "\n",
    "    def evaluate(self, X, y):\n",
    "        correct = sum(self.predict(x) == y[i] for i, x in enumerate(X))\n",
    "        accuracy = correct / len(y)\n",
    "        return accuracy\n",
    "\n",
    "# NAND Gate Truth Table\n",
    "X_nand = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "y_nand = np.array([1, 1, 1, 0]) #Output of NAND gate\n",
    "\n",
    "# XOR Gate Truth Table\n",
    "X_xor = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "y_xor = np.array([0, 1, 1, 0]) #Output of XOR gate\n",
    "\n",
    "# Train and evaluate perceptron for NAND\n",
    "discrete_perceptron = Perceptron(input_size=2)\n",
    "discrete_perceptron.train(X_nand, y_nand)\n",
    "nand_accuracy = discrete_perceptron.evaluate(X_nand, y_nand)\n",
    "print(f\"NAND Perceptron Accuracy: {nand_accuracy * 100:.2f}%\")\n",
    "\n",
    "# Train and evaluate perceptron for XOR\n",
    "xor_perceptron = Perceptron(input_size=2)\n",
    "xor_perceptron.train(X_xor, y_xor)\n",
    "xor_accuracy = xor_perceptron.evaluate(X_xor, y_xor)\n",
    "print(f\"XOR Perceptron Accuracy: {xor_accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description of the Code\n",
    "\n",
    "Uses a step activation function to predict binary outputs (0 or 1).\n",
    "\n",
    "* 1 if input>= 0\n",
    "* 0 otherwise\n",
    "\n",
    "Perceptron Class:\n",
    "\n",
    "* Initializes random weights (including bias).\n",
    "* Implements forward pass for prediction.\n",
    "* Uses Perceptron Learning Rule to update weights during training.\n",
    "* Stops early if training converges (error = 0).\n",
    "\n",
    "Prediction Function:\n",
    "\n",
    "* Adds a bias to input.\n",
    "* Computes weighted sum and applies step function.\n",
    "\n",
    "Training Function:\n",
    "\n",
    "* Iterates through epochs, updating weights using Perceptron Learning Rule.\n",
    "* Stops early if no errors are found.\n",
    "\n",
    "Datasets:\n",
    "\n",
    "* NAND Gate is Linearly separable \n",
    "* XOR Gate is Not linearly separable \n",
    "\n",
    "Training:\n",
    "\n",
    "Perceptron trains on NAND and XOR datasets separately.\n",
    "\n",
    "Performance Evaluation:\n",
    "\n",
    "* Accuracy of NAND gate is 100% and that of XOR is 50%.\n",
    "* NAND gate is linearly seperable by perceptron while XOR is not linearly seperable by perceptron."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### My Comments\n",
    "\n",
    "The Perceptron cannot solve XOR because a single-layer perceptron cannot handle non-linearly separable data.\n",
    "\n",
    "Possible Improvements:\n",
    "* Use a Multi-Layer Perceptron (MLP) with a hidden layer.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
