{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### WAP to implement a multi-layer perceptron (MLP) network with one hidden layer using numpy in Python. Demonstrate that it can learn the XOR Boolean function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description of the Model:\n",
    "A Multi-Layer Perceptron (MLP) is a class of feedforward artificial neural networks (ANN). It consists of an input layer, one or more hidden layers, and an output layer. For this implementation:\n",
    "\n",
    "* XOR is non-linear seperable means it cannot be seperable by single layer perceptron, so we use multi-layer perceptron with hidden layer\n",
    "* The input layer has 2 neurons.\n",
    "* The hidden layer has 4 neurons with step activation functions.\n",
    "* The output layer has 1 neuron with a step activation function.\n",
    "* It does not use backpropagation instead  weight update rule is applied when the output is incorrect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [0 1 1 0]\n",
      "Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def step_function(x):\n",
    "    # Step activation function:\n",
    "    return np.where(x >= 0, 1, 0)\n",
    "\n",
    "def train_mlp(X, y, hidden_neurons=4, epochs=10000, learning_rate=0.01):\n",
    "    input_neurons = X.shape[1]\n",
    "    output_neurons = 1\n",
    "    \n",
    "    # Initialize weights and biases randomly\n",
    "    W1 = np.random.uniform(-1, 1, (hidden_neurons, input_neurons))\n",
    "    b1 = np.random.uniform(-1, 1, (hidden_neurons, 1)) \n",
    "    W2 = np.random.uniform(-1, 1, (output_neurons, hidden_neurons))\n",
    "    b2 = np.random.uniform(-1, 1, (output_neurons, 1))\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for i in range(X.shape[0]):\n",
    "            x_sample = X[i].reshape(-1, 1)\n",
    "            y_sample = y[i]\n",
    "            \n",
    "            # Forward pass\n",
    "            hidden_input = np.dot(W1, x_sample) + b1\n",
    "            hidden_output = step_function(hidden_input)\n",
    "            final_input = np.dot(W2, hidden_output) + b2\n",
    "            final_output = step_function(final_input)\n",
    "            \n",
    "            # Random weight update rule\n",
    "            if final_output != y_sample:\n",
    "                W2 += learning_rate * (y_sample - final_output) * hidden_output.T\n",
    "                b2 += learning_rate * (y_sample - final_output)\n",
    "                W1 += learning_rate * (y_sample - final_output) * x_sample.T\n",
    "                b1 += learning_rate * (y_sample - final_output)\n",
    "    \n",
    "    return W1, b1, W2, b2\n",
    "\n",
    "def predict(X, W1, b1, W2, b2):\n",
    "    hidden_input = np.dot(W1, X.T) + b1\n",
    "    hidden_output = step_function(hidden_input)\n",
    "    final_input = np.dot(W2, hidden_output) + b2\n",
    "    final_output = step_function(final_input)\n",
    "    return final_output.T\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    return np.mean(y_true == y_pred) * 100\n",
    "\n",
    "# XOR dataset\n",
    "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "y = np.array([[0], [1], [1], [0]]) # output of XOR gate\n",
    "\n",
    "# Train the MLP\n",
    "W1, b1, W2, b2 = train_mlp(X, y, hidden_neurons=4)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = predict(X, W1, b1, W2, b2)\n",
    "\n",
    "# Compute accuracy\n",
    "acc = accuracy(y, y_pred)\n",
    "\n",
    "# Print results\n",
    "print(\"Predictions:\", y_pred.flatten())\n",
    "print(f\"Accuracy: {acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description of the code\n",
    "\n",
    "Use Step function to predict binary output i.e 0 and 1\n",
    " * 1 when x>=0\n",
    " * 0 otherwise\n",
    "\n",
    "Initialize weights and biases \n",
    " * W1 and b1 are weights and biases of the hidden layer.\n",
    " * W2 and b2 are weights and biases of the output layer.\n",
    " * Weights are initialized randomly between -1 and 1. \n",
    "\n",
    "##### Error: y_sample- final_output\n",
    "##### weight-update rule: w = w+ learning_rate * error * X.T\n",
    "\n",
    " \n",
    "* Epoch: We have train the model 10,000 times to improve accuracy. It iterate each time and adjust weights and biases.\n",
    "* Learning rate controls how much the weights change.\n",
    "\n",
    "Forward Pass:\n",
    " * It compute the values for hidden layer and output layer.\n",
    " * Applied step function to get binary outputs.\n",
    "\n",
    "Weight Update Rule:\n",
    " * It adjust weights randomly when the output is wrong.\n",
    "\n",
    "The accuracy of XOR by MLP is 100% after training.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Evaluation:\n",
    "\n",
    "* Accuracy: The model have achieved 100% accuracy for XOR.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### My Comments:\n",
    "\n",
    "Limitations: \n",
    "* For the accuracy we have to increase number of epochs or learning rate to get the desired accuracy and that can led to overfitting.\n",
    "* Some training runs may not achieve the desired accuracy.\n",
    "\n",
    "Improvements: \n",
    "* We can implement Backpropagation with gradient descent instead of weight update rule.\n",
    "* Use Sigmoid, ReLU like activation functions for better learning.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
